{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":86023,"databundleVersionId":11376393,"sourceType":"competition"},{"sourceId":256574,"sourceType":"modelInstanceVersion","modelInstanceId":204042,"modelId":225262}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nfrom datasets import Dataset\ndf = pd.read_csv('/kaggle/input/ai-mathematical-olympiad-progress-prize-2/reference.csv')\ndf = df[['problem', 'answer']]\ndf.rename(columns={'problem':'question'}, inplace=True)\ndf.head()","metadata":{"_uuid":"8e5a9023-b1ee-406c-a0b0-adfd911f0137","_cell_guid":"fc7d12bf-f8c1-4b01-8d7b-d9f9a05e1e14","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-03-22T23:21:44.343870Z","iopub.execute_input":"2025-03-22T23:21:44.344220Z","iopub.status.idle":"2025-03-22T23:21:46.587112Z","shell.execute_reply.started":"2025-03-22T23:21:44.344168Z","shell.execute_reply":"2025-03-22T23:21:46.586094Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"execution_count":1,"output_type":"execute_result","data":{"text/plain":"                                            question  answer\n0  Three airline companies operate flights from D...      79\n1  Fred and George take part in a tennis tourname...     250\n2  Triangle $ABC$ has side length $AB = 120$ and ...     180\n3  Find the three-digit number $n$ such that writ...     143\n4  We call a sequence $a_1, a_2, \\ldots$ of non-n...       3","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>question</th>\n      <th>answer</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Three airline companies operate flights from D...</td>\n      <td>79</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Fred and George take part in a tennis tourname...</td>\n      <td>250</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Triangle $ABC$ has side length $AB = 120$ and ...</td>\n      <td>180</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Find the three-digit number $n$ such that writ...</td>\n      <td>143</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>We call a sequence $a_1, a_2, \\ldots$ of non-n...</td>\n      <td>3</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":1},{"cell_type":"code","source":"df['answer'] = df['answer'].astype(str)\ndf['answer'] = '#### ' + df['answer']\n\n# Ensure question is string as well\ndf['question'] = df['question'].astype(str)\n\n# Convert to HF Dataset\ncustom_dataset = Dataset.from_pandas(df)","metadata":{"_uuid":"a82d8226-eec6-49b7-8136-38612175e105","_cell_guid":"18169107-21ed-42e4-881d-aa0929ba76af","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-03-22T23:21:46.588528Z","iopub.execute_input":"2025-03-22T23:21:46.588888Z","iopub.status.idle":"2025-03-22T23:21:46.604345Z","shell.execute_reply.started":"2025-03-22T23:21:46.588856Z","shell.execute_reply":"2025-03-22T23:21:46.603296Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# ðŸ“ LaTRO Kaggle Notebook with Full RLOO + SFT Loss + KL Penalty + Save Model + Full Truncation + Chat Template Logic\n\nfrom dataclasses import dataclass, field\nfrom typing import Optional, List, Literal\nimport torch\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\nfrom datasets import load_dataset, Dataset\nfrom accelerate import Accelerator\n\n# --- CONFIG ---\n@dataclass\nclass TrainerConfig:\n    exp_name: str = \"latro_kaggle_exp_1\"\n    run_name: Optional[str] = None\n    model_name_or_path: str = '/kaggle/input/deepseek-r1/transformers/deepseek-r1-distill-qwen-1.5b/2'#\"EleutherAI/pythia-160m\"\n    dataset_name: Literal[\"gsm8k\"] = \"gsm8k\"\n    total_episodes: Optional[int] = None\n    num_train_epochs: int = 1\n    num_evaluations: int = 2\n    per_device_train_batch_size: int = 2\n    per_device_eval_batch_size: int = 2\n    rollout_batch_size: int = 2\n    gradient_accumulation_steps: int = 1\n    learning_rate: float = 5e-7\n    rloo_k: int = 2\n    kl_coef: float = 0.05\n    response_length: int = 200\n    stop_token: Optional[str] = \"both\"\n    stop_token_ids: Optional[List[int]] = None\n    temperature: float = 1.0\n    sft_penalty: float = 0.1\n    sanity_check: bool = True\n\nconfig = TrainerConfig()\n\n# --- TOKENIZER + MODEL ---\ntokenizer = AutoTokenizer.from_pretrained(config.model_name_or_path, padding_side=\"left\")\nmodel = AutoModelForCausalLM.from_pretrained(config.model_name_or_path, torch_dtype=torch.float16)\nref_model = AutoModelForCausalLM.from_pretrained(config.model_name_or_path, torch_dtype=torch.float16).to('cpu')\nif tokenizer.pad_token is None:\n    tokenizer.pad_token = tokenizer.eos_token\n\nstop_sequences = [\"The answer is\", \"####\", \"Answer:\"]\nstop_token_ids = [tokenizer.encode(seq, add_special_tokens=False) for seq in stop_sequences]\n\n# --- CHAT TEMPLATE LOGIC ---\ndef apply_chat_template(question: str) -> str:\n    messages = [{\"role\": \"system\", \"content\": \"Think step-by-step to arrive at the correct answer. Write down each thinking step. Only keep a minimum draft for each thinking step, with 5 words at most. Return final answer within \\\\boxed{}, after taking modulo 1000.\"},\n                {\"role\": \"user\", \"content\": question},\n            ]\n    return tokenizer.apply_chat_template(\n            conversation=messages,\n            tokenize=False,\n            add_generation_prompt=True)\n\n# --- DATASET ---\ndef prepare_dataset_gsm8k(dataset: Dataset, tokenizer):\n    queries = [apply_chat_template(q) for q in dataset[\"question\"]]\n    responses = [f\"The answer is {a.split('#### ')[-1].strip()}\" for a in dataset[\"answer\"]]\n    return Dataset.from_dict({\"queries\": queries, \"responses\": responses})\n\n#raw = load_dataset(\"openai/gsm8k\", name=\"main\")\ntrain_dataset = prepare_dataset_gsm8k(custom_dataset.select(range(8)), tokenizer)\neval_dataset = prepare_dataset_gsm8k(custom_dataset.select(range(8,10)), tokenizer)\n\n# --- TRAINER ---\nclass FullLatroTrainer:\n    def __init__(self, model, ref_model, tokenizer, train_ds, eval_ds, config):\n        self.model = model\n        self.ref_model = ref_model\n        self.tokenizer = tokenizer\n        self.train_ds = train_ds\n        self.eval_ds = eval_ds\n        self.config = config\n        self.accelerator = Accelerator()\n\n        self.train_loader = DataLoader(train_ds, batch_size=1, shuffle=True)\n        self.eval_loader = DataLoader(eval_ds, batch_size=1)\n\n        self.model = self.accelerator.prepare(self.model)\n        self.ref_model = self.ref_model.to(self.accelerator.device)\n        self.model.gradient_checkpointing_enable()\n\n\n    def truncate_response(self, sequences):\n        truncated = []\n        for seq in sequences:\n            found = False\n            for stop_ids in stop_token_ids:\n                stop_len = len(stop_ids)\n                for i in range(len(seq) - stop_len + 1):\n                    if torch.equal(seq[i:i+stop_len], torch.tensor(stop_ids, device=seq.device)):\n                        truncated.append(torch.cat([seq[:i+stop_len], torch.full((len(seq)-i-stop_len,), tokenizer.pad_token_id, device=seq.device)]))\n                        found = True\n                        break\n                if found: \n                    break\n            if not found:\n                truncated.append(seq)\n        return torch.stack(truncated)\n\n    def compute_logprobs(self, model, inputs, labels, context_lengths):\n        outputs = model(**inputs)\n        logits = outputs.logits[:, :-1]\n\n        # Align log_probs length with target length\n        target = labels[\"input_ids\"][:, 1:]\n        log_probs = F.log_softmax(logits, dim=-1)\n        log_probs = log_probs[:, -target.shape[1]:, :]\n\n        mask = torch.arange(target.shape[1]).unsqueeze(0).to(target.device) >= context_lengths.unsqueeze(1)\n        loss = F.nll_loss(log_probs.reshape(-1, log_probs.size(-1)), target.reshape(-1), reduction='none')\n        loss = loss.view(target.shape)\n        loss = loss.masked_fill(mask, 0.0)\n\n        return loss.sum(1), log_probs, target, mask\n\n    def train(self):\n        optimizer = torch.optim.AdamW(self.model.parameters(), lr=config.learning_rate)\n        for epoch in range(self.config.num_train_epochs):\n            for batch in self.train_loader:\n                inputs = self.tokenizer(batch[\"queries\"], return_tensors=\"pt\", padding=True).to(self.accelerator.device)\n                labels = self.tokenizer(batch[\"responses\"], return_tensors=\"pt\", padding=True).to(self.accelerator.device)\n                context_lengths = (inputs[\"input_ids\"] != tokenizer.pad_token_id).sum(dim=1)\n\n                # Repeat queries and labels for RLOO sampling\n                inputs[\"input_ids\"] = inputs[\"input_ids\"].repeat_interleave(config.rloo_k, dim=0)\n                labels[\"input_ids\"] = labels[\"input_ids\"].repeat_interleave(config.rloo_k, dim=0)\n                context_lengths = context_lengths.repeat_interleave(config.rloo_k, dim=0)\n\n                rewards = []\n                ref_rewards = []\n                for _ in range(config.rloo_k):\n                    unwrapped_model = self.accelerator.unwrap_model(self.model)\n                    generation = unwrapped_model.generate(**inputs, max_new_tokens=config.response_length)\n                    generation = self.truncate_response(generation)\n\n                    model_lp, model_log_probs, targets, mask = self.compute_logprobs(self.model, {\"input_ids\": generation}, labels, context_lengths)\n                    with torch.no_grad():\n                        ref_lp, _, _, _ = self.compute_logprobs(self.ref_model, {\"input_ids\": generation}, labels, context_lengths)\n\n                    rewards.append(-model_lp)\n                    ref_rewards.append(-ref_lp)\n\n                rewards = torch.stack(rewards, dim=1)\n                ref_rewards = torch.stack(ref_rewards, dim=1)\n\n                baseline = (rewards.sum(1, keepdim=True) - rewards) / (config.rloo_k - 1)\n                advantages = rewards - baseline\n\n                # KL penalty\n                kl_penalty = -config.kl_coef * (rewards - ref_rewards)\n                advantages += kl_penalty\n\n                rloo_loss = (advantages * rewards).mean()\n\n                # SFT loss\n                sft_loss, *_ = self.compute_logprobs(self.model, inputs, labels, context_lengths)\n                sft_loss = sft_loss.mean()\n\n                total_loss = rloo_loss + config.sft_penalty * sft_loss\n                self.accelerator.backward(total_loss)\n                optimizer.step()\n                optimizer.zero_grad()\n                print(f\"Epoch {epoch} RLOO Loss: {rloo_loss.item():.4f} | SFT Loss: {sft_loss.item():.4f} | KL Penalty: {kl_penalty.mean().item():.4f}\")\n\n    def evaluate(self):\n        self.model.eval()\n        with torch.no_grad():\n            for batch in self.eval_loader:\n                inputs = self.tokenizer(batch[\"queries\"], return_tensors=\"pt\", padding=True).to(self.accelerator.device)\n                unwrapped_model = self.accelerator.unwrap_model(self.model)\n                generated = unwrapped_model.generate(**inputs, max_new_tokens=500)\n                truncated = self.truncate_response(generated)\n                decoded = self.tokenizer.batch_decode(truncated, skip_special_tokens=True)\n                print(f\"Q: {batch['queries'][0]} \\nA: {decoded[0]}\")\n\n    def save_model(self, save_dir=\"./saved_model\"):\n        self.accelerator.wait_for_everyone()\n        if self.accelerator.is_main_process:\n            self.model.save_pretrained(save_dir)\n            self.tokenizer.save_pretrained(save_dir)\n            print(f\"Model saved to {save_dir}\")","metadata":{"_uuid":"cdb78080-7f60-423d-9937-1a470dcbabe2","_cell_guid":"636c4f9e-3160-4c31-90f0-725427beb536","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-03-22T19:51:00.780531Z","iopub.execute_input":"2025-03-22T19:51:00.780742Z","iopub.status.idle":"2025-03-22T19:51:29.335914Z","shell.execute_reply.started":"2025-03-22T19:51:00.780725Z","shell.execute_reply":"2025-03-22T19:51:29.335214Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# --- RUN TRAINING ---\ntrainer = FullLatroTrainer(model, ref_model, tokenizer, train_dataset, eval_dataset, config)","metadata":{"_uuid":"bcea552d-1c61-48e0-b2a3-f9a18b1b7e9a","_cell_guid":"a4eb9fb8-3aca-4dca-af61-307d882780e3","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-03-22T19:51:29.336727Z","iopub.execute_input":"2025-03-22T19:51:29.336940Z","iopub.status.idle":"2025-03-22T19:51:31.384546Z","shell.execute_reply.started":"2025-03-22T19:51:29.336922Z","shell.execute_reply":"2025-03-22T19:51:31.383807Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"trainer.train()","metadata":{"_uuid":"dbf818d6-1d85-4e70-ae8a-dd574894192f","_cell_guid":"63a9aea3-481e-47cd-8f1d-a2aee20a5d0c","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-03-22T19:51:31.385262Z","iopub.execute_input":"2025-03-22T19:51:31.385483Z","iopub.status.idle":"2025-03-22T19:51:56.011899Z","shell.execute_reply.started":"2025-03-22T19:51:31.385465Z","shell.execute_reply":"2025-03-22T19:51:56.010870Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"trainer.evaluate()\ntrainer.save_model(\"./latro_final_checkpoint\")","metadata":{"_uuid":"8d70e809-8531-446e-8aa4-836f858e4951","_cell_guid":"385b8890-b050-4475-848a-ea5fcfe010c2","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-03-22T20:29:50.707367Z","iopub.execute_input":"2025-03-22T20:29:50.707713Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null}]}